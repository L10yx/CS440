{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS440/ECE448 Spring 2024\n",
    "# MP01: Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you need to do is to download this file: <a href=\"mp01.zip\">mp01.zip</a>.  It has the following content:\n",
    "\n",
    "* `submitted.py`: Your homework. Edit, and then submit to <a href=\"https://www.gradescope.com/courses/486387\">Gradescope</a>.\n",
    "* `mp01_notebook.ipynb`: This is a <a href=\"https://anaconda.org/anaconda/jupyter\">Jupyter</a> notebook to help you debug.  You can completely ignore it if you want, although you might find that it gives you useful instructions.\n",
    "* `grade.py`: Once your homework seems to be working, you can test it by typing `python grade.py`, which will run the tests in `tests/tests_visible.py`.\n",
    "* `tests/test_visible.py`: This file contains about half of the <a href=\"https://docs.python.org/3/library/unittest.html\">unit tests</a> that Gradescope will run in order to grade your homework.  If you can get a perfect score on these tests, then you should also get a perfect score on the additional hidden tests that Gradescope uses.\n",
    "* `solution.json`: This file contains the solutions for the visible test cases, in <a href=\"https://docs.python.org/3/library/json.html\">JSON</a> format.  If the instructions are confusing you, please look at this file, to see if it can help to clear up your confusion.\n",
    "* `data`: This directory contains the data.\n",
    "* `reader.py`: This is an auxiliary program that you can use to read the data.\n",
    "* `requirements.txt`: This tells you which python packages you need to have installed, in order to run `grade.py`.  You can install all of those packages by typing `pip install -r requirements.txt` or `pip3 install -r requirements.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file (`mp01_notebook.ipynb`) will walk you through the whole MP, giving you instructions and debugging tips as you go.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. <a href=\"#section1\">Reading the data</a>\n",
    "1. <a href=\"#section2\">Joint and Conditional Distributions</a>\n",
    "1. <a href=\"#section3\">Mean, Variance and Covariance</a>\n",
    "1. <a href=\"#section4\">Expected Value of a Function of an RV</a>\n",
    "1. <a href=\"#grade\">Grade Your Homework</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of data: visible data (provided to you), and hidden data (available only to the autograder on Gradescope).  If you get your code working for the visible data, it should also work for the hidden data.\n",
    "\n",
    "The visible dataset consist of 500 emails, a subset of the <a href=\"https://www.kaggle.com/datasets/wanderfj/enron-spam\">Enron-Spam dataset</a> provided by Ion Androutsopoulos. MP02 will use a larger portion of the same dataset.\n",
    "\n",
    "In order to help you load the data, we provide you with a utility function called `reader.py`.  To use it, you will need to install nltk.  It should be possible for you to do this by running the following code block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/linyuxuan/anaconda3/lib/python3.11/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in /Users/linyuxuan/anaconda3/lib/python3.11/site-packages (from nltk) (8.0.4)\r\n",
      "Requirement already satisfied: joblib in /Users/linyuxuan/anaconda3/lib/python3.11/site-packages (from nltk) (1.2.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/linyuxuan/anaconda3/lib/python3.11/site-packages (from nltk) (2022.7.9)\r\n",
      "Requirement already satisfied: tqdm in /Users/linyuxuan/anaconda3/lib/python3.11/site-packages (from nltk) (4.65.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code we provide, and most of the template code that you need to fill in, will be documented using docstrings so you can find information about each function by using `help`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module reader:\n",
      "\n",
      "NAME\n",
      "    reader - This file is responsible for providing functions for reading the files\n",
      "\n",
      "FUNCTIONS\n",
      "    loadDir(dirname, stemming, lower_case, use_tqdm=True)\n",
      "        Loads the files in the folder and returns a \n",
      "        list of lists of words from the text in each file.\n",
      "        \n",
      "        Parameters:\n",
      "        name (str): the directory containing the data\n",
      "        stemming (bool): if True, use NLTK's stemmer to remove suffixes\n",
      "        lower_case (bool): if True, convert letters to lowercase\n",
      "        use_tqdm (bool, default:True): if True, use tqdm to show status bar\n",
      "        \n",
      "        Output:\n",
      "        texts (list of lists): texts[m][n] is the n'th word in the m'th email\n",
      "        count (int): number of files loaded\n",
      "    \n",
      "    loadFile(filename, stemming, lower_case)\n",
      "        Load a file, and returns a list of words.\n",
      "        \n",
      "        Parameters:\n",
      "        filename (str): the directory containing the data\n",
      "        stemming (bool): if True, use NLTK's stemmer to remove suffixes\n",
      "        lower_case (bool): if True, convert letters to lowercase\n",
      "        \n",
      "        Output:\n",
      "        x (list): x[n] is the n'th word in the file\n",
      "\n",
      "DATA\n",
      "    bad_words = {'aed', 'eed', 'oed'}\n",
      "    porter_stemmer = <PorterStemmer>\n",
      "    tokenizer = RegexpTokenizer(pattern='\\\\w+', gaps=False, disc...ty=True...\n",
      "\n",
      "FILE\n",
      "    /Users/linyuxuan/Downloads/mp01/reader.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import reader\n",
    "help(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's pretty straightforward.   Let's use it to load the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 500/500 [00:00<00:00, 30500.92it/s]\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(reader)\n",
    "texts, count = reader.loadDir('data',False,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 500 files loaded\n"
     ]
    }
   ],
   "source": [
    "print(\"There were\",count,\"files loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first file contained the following words: ['Subject', 'done', 'new', 'sitara', 'desk', 'request', 'ref', 'cc', '20000813', 'carey', 'per', 'scott', 's', 'request', 'below', 'the', 'following', 'business', 'unit', 'aka', 'desk', 'id', 'portfolio', 'was', 'added', 'to', 'global', 'production', 'and', 'unify', 'development', 'test', 'production', 'and', 'stage', 'please', 'copy', 'to', 'the', 'other', 'global', 'environments', 'thanks', 'dick', 'x', '3', '1489', 'updated', 'in', 'global', 'production', 'environment', 'gcc', 'code', 'desc', 'p', 'ent', 'subenti', 'data', '_', 'cd', 'ap', 'data', '_', 'desc', 'code', '_', 'id', 'a', 'sit', 'deskid', 'imcl', 'a', 'ena', 'im', 'cleburne', '9273', 'from', 'scott', 'mills', '08', '30', '2000', '08', '27', 'am', 'to', 'samuel', 'schott', 'hou', 'ect', 'ect', 'richard', 'elwood', 'hou', 'ect', 'ect', 'debbie', 'r', 'brackett', 'hou', 'ect', 'ect', 'judy', 'rose', 'hou', 'ect', 'ect', 'vanessa', 'schulte', 'corp', 'enron', 'enron', 'david', 'baumbach', 'hou', 'ect', 'ect', 'daren', 'j', 'farmer', 'hou', 'ect', 'ect', 'dave', 'nommensen', 'hou', 'ect', 'ect', 'donna', 'greif', 'hou', 'ect', 'ect', 'shawna', 'johnson', 'corp', 'enron', 'enron', 'russ', 'severson', 'hou', 'ect', 'ect', 'cc', 'subject', 'new', 'sitara', 'desk', 'request', 'this', 'needs', 'to', 'be', 'available', 'in', 'production', 'by', 'early', 'afternoon', 'sorry', 'for', 'the', 'short', 'notice', 'srm', 'x', '33548']\n"
     ]
    }
   ],
   "source": [
    "print(\"The first file contained the following words:\",texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint, Conditional, and Marginal Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this week's MP, we will work with the following two random variables:\n",
    "\n",
    "* $X_1=$ the number of times that word1 occurs in a text\n",
    "* $X_2=$ the number of times that word2 occurs in a text\n",
    "\n",
    "... where you can specify word1 and word2 as parameters of the function.  In this section, we will compute the joint, conditional, and marginal distributions of $X_1$ and $X_2$.  These will be estimated, from the available data, using the following formulas, where $N(X_1=x_1,X_2=x_2)$ is the number of texts in the dataset that contain $x_1$ instances of word1, and $x_2$ instances of word2:\n",
    "\n",
    "#### Joint distribution:\n",
    "\n",
    "$$P(X_1=x_1,X_2=x_2)=\\frac{N(X_1=x_1,X_2=x_2)}{\\sum_{x_1}\\sum_{x_2} N(X_1=x_1,X_2=x_2)}$$\n",
    "\n",
    "#### Marginal distributions:\n",
    "\n",
    "$$P(X_1=x_1)=\\sum_{x_2} P(X_1=x_1,X_2=x_2)$$\n",
    "$$P(X_2=x_2)=\\sum_{x_1} P(X_1=x_1,X_2=x_2)$$\n",
    "\n",
    "#### Conditional distribution:\n",
    "\n",
    "$$P(X_2=x_2|X_1=x_1)=\\frac{P(X_1=x_1,X_2=x_2)}{P(X_1=x_1)}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we'll load the file `submitted.py`.\n",
    "\n",
    "The file `submitted.py` is the only part of your work that the autograder will see. The only purpose of this notebook is to help you debug `submitted.py`.  Once you have revised `submitted.py` enough to make this notebook work, then you should go to the command line, and type `python grade.py`.  Once that command returns without errors, then  you can go ahead and submit your file `submitted.py` to the autograder.  You can submit to the autograder as often as you want, but it will save you trouble if you debug as much as you can on your local machine, before you submit to the autograder.\n",
    "\n",
    "We will use `importlib` in order to reload your `submitted.py` over and over again.  That way, every time you make a modification in `submitted.py`, you can just re-run  the corresponding block of this notebook, and it will reload `submitted.py` with your modified code.  \n",
    "\n",
    "Since the file is called `submitted.py`, python considers it to contain a module called `submitted`.  As shown, you can read the module's docstring by printing `submitted.__doc__`.  You can also type `help(submitted)` to get a lot of information about the module, including its docstring, a list of all the functions it defines, and all of their docstrings.  For  more about docstrings, see, for example, https://www.python.org/dev/peps/pep-0257/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the module you'll submit to the autograder.\n",
      "\n",
      "There are several function definitions, here, that raise RuntimeErrors.  You should replace\n",
      "each \"raise RuntimeError\" line with a line that performs the function specified in the\n",
      "function's docstring.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import submitted\n",
    "import importlib\n",
    "importlib.reload(submitted)\n",
    "print(submitted.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for you to open `submitted.py`, and start editing it.  You can open it in another Jupyter window by choosing \"Open from Path\" from the \"File\" menu, and then typing `submitted.py`.  Alternatively, you can use any text editor.\n",
    "\n",
    "Once you have it open, try editing the function `marginal_distribution_of_word_counts` so that its functionality matches its docstring.  Here is what it's docstring says:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function marginal_distribution_of_word_counts in module submitted:\n",
      "\n",
      "marginal_distribution_of_word_counts(texts, word0)\n",
      "    Parameters:\n",
      "    texts (list of lists) - a list of texts; each text is a list of words\n",
      "    word0 (str) - the word that you want to count\n",
      "    \n",
      "    Output:\n",
      "    Pmarginal (numpy array of length cX0) - Pmarginal[x0] = P(X0=x0), where\n",
      "      X0 is the number of times that word0 occurs in a document\n",
      "      cX0-1 is the largest value of X0 observed in the provided texts\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(submitted.marginal_distribution_of_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit `marginal_distribution_of_word_counts` so that it does the task specified in its docstring.  When you get the code working, you can count the number of times that the word \"company\" occurs in any given document once, twice, thrice, etc.  It turns out that only 2.4% of texts contain the word \"company\" just once, 0.2% contain it twice, 0.2% contain it four times; 97.2% don't contain it at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.972 0.024 0.002 0.    0.002]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "Pmarginal = submitted.marginal_distribution_of_word_counts(texts, 'company')\n",
    "print(Pmarginal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, edit the function `conditional_distribution_of_word_counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function conditional_distribution_of_word_counts in module submitted:\n",
      "\n",
      "conditional_distribution_of_word_counts(texts, word0, word1)\n",
      "    Parameters:\n",
      "    texts (list of lists) - a list of texts; each text is a list of words\n",
      "    word0 (str) - the first word that you want to count\n",
      "    word1 (str) - the second word that you want to count\n",
      "    \n",
      "    Outputs: \n",
      "    Pcond (numpy array, shape=(cX0,cX1)) - Pcond[x0,x1] = P(X1=x1|X0=x0), where\n",
      "      X0 is the number of times that word0 occurs in a document\n",
      "      cX0-1 is the largest value of X0 observed in the provided texts\n",
      "      X1 is the number of times that word1 occurs in a document\n",
      "      cX1-1 is the largest value of X0 observed in the provided texts\n",
      "      CAUTION: If P(X0=x0) is zero, then P(X1=x1|X0=x0) should be np.nan.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.conditional_distribution_of_word_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that, according to the definition of conditional probability, any probability conditioned on the event $X_0=3$ is undefined, because $P(X_0=3)=0$.  In such cases, your code should return a value of `np.nan`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.97942387 0.01234568 0.00617284 0.00205761]\n",
      " [0.83333333 0.16666667 0.         0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [       nan        nan        nan        nan]\n",
      " [1.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "Pcond = submitted.conditional_distribution_of_word_counts(texts, \"company\", \"sales\")\n",
    "print(Pcond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, consider the function `joint_distribution_of_word_counts`, which uses the marginal and conditional probability tables as inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function joint_distribution_of_word_counts in module submitted:\n",
      "\n",
      "joint_distribution_of_word_counts(Pmarginal, Pcond)\n",
      "    Parameters:\n",
      "    Pmarginal (numpy array of length cX0) - Pmarginal[x0] = P(X0=x0), where\n",
      "    Pcond (numpy array, shape=(cX0,cX1)) - Pcond[x0,x1] = P(X1=x1|X0=x0)\n",
      "    \n",
      "    Output:\n",
      "    Pjoint (numpy array, shape=(cX0,cX1)) - Pjoint[x0,x1] = P(X0=x0, X1=x1)\n",
      "      X0 is the number of times that word0 occurs in a given text,\n",
      "      X1 is the number of times that word1 occurs in the same text.\n",
      "      CAUTION: if P(X0=x0) then P(X0=x0,X1=x1)=0, even if P(X1=x1|X0=x0)=np.nan.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.joint_distribution_of_word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.952 0.012 0.006 0.002]\n",
      " [0.02  0.004 0.    0.   ]\n",
      " [0.002 0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.002 0.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "Pjoint = submitted.joint_distribution_of_word_counts(Pmarginal,Pcond)\n",
    "print(Pjoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Vector and Covariance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to study mean, variance and covariance, let's first find the joint distribution of some pair of words that occur more frequently.  How about \"a\" and \"the\"?  Amazingly, as the following code shows, there is a small nonzero probability that \"a\" occurs 19 times, and \"the\" occurs 58 times, in the same text!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the joint distribution:\n",
      "[[0.248 0.078 0.056 ... 0.    0.    0.   ]\n",
      " [0.036 0.028 0.026 ... 0.    0.    0.   ]\n",
      " [0.006 0.006 0.014 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [0.    0.    0.    ... 0.    0.    0.   ]\n",
      " [0.    0.    0.    ... 0.    0.    0.002]]\n",
      "\n",
      " It has size (20, 59)\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "Pa = submitted.marginal_distribution_of_word_counts(texts, 'a')\n",
    "Pthe_given_a = submitted.conditional_distribution_of_word_counts(texts, 'a', 'the')\n",
    "Pa_the = submitted.joint_distribution_of_word_counts(Pa, Pthe_given_a)\n",
    "\n",
    "print(\"Here is the joint distribution:\")\n",
    "print(Pa_the)\n",
    "print(\"\\n It has size\", Pa_the.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot this distribution as a 2d plot using matplotlib.  First, make sure you have matplotlib installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cX0, cX1 = Pa_the.shape\n",
    "x, y = np.meshgrid(np.arange(cX0), np.arange(cX1))\n",
    "base = np.zeros((cX0, cX1))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.bar3d(x.ravel(), y.ravel(), base.ravel(), 1, 1, Pa_the.ravel(), shade=True)\n",
    "ax.set_title(\"Counts of the word /the/ have the following probability mass function:\")\n",
    "ax.set_xlabel(\"$x_0=$ frequency of /a/\")\n",
    "ax.set_ylabel(\"$x_1=$ frequency of /the/\")\n",
    "ax.set_zlabel(\"$P(X_0=x_0,X_1=x_1)$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the mean vector will be pretty close to $\\mu=[0,0]$.  Let's find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.mean_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(submitted)\n",
    "mu = submitted.mean_vector(Pa_the)\n",
    "print(mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a bit of a surprise - the mean of $X_1$ is higher than the mean of $X_0$!  That result wasn't obvious in the figure, unless you noticed that the maximum value of $X_1$ is 58, while the maximum value of $X_0$ is only 19.  \n",
    "\n",
    "Now let's try to find the matrix of variances and covariances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(submitted)\n",
    "Sigma = submitted.covariance_matrix(Pa_the, mu)\n",
    "print(Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to notice:\n",
    "\n",
    "* The variance of $X_1$ is larger than the variance of $X_0$.  This is because $X_1$ varies over a larger range than $X_0$, with nonzero probabilities all the way.\n",
    "* The covariance of $X_0$ and $X_1$ is positive, meaning that a large value of $X_0$ tends to co-occur with a large value of $X_1$.  Probably, this just means that long texts have larger counts of both the words `a` and `the`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Function of Random Variables is a Random Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's calculate a new random variable by taking a function of the random variables $X_0$ and $X_1$.  Any function of random variables is a random variable, and its distribution is\n",
    "\n",
    "$$P(f(X_0,X_1)=z)=\\sum_{x_0,x_1:f(x_0,x_1)=z} P(X_0=x_0,X_1=x_1)$$\n",
    "\n",
    "Let's read the docstring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.distribution_of_a_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read about defaultdict and Counter data types `here <https://docs.python.org/3/library/collections.html>`_.  Basically, they are just dictionaries with a default value for any previously unseen keys.\n",
    "\n",
    "Let's create a new random variable whose value is a string, rather than being a number.  Here is the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x0,x1):\n",
    "    if x0<1 and x1 < 1:\n",
    "        return \"Zero\"\n",
    "    elif x0 < 2 and x1 < 2:\n",
    "        return \"Small\"\n",
    "    else:\n",
    "        return \"Big\"\n",
    "\n",
    "print(\"f(0,0)=\",f(0,0))\n",
    "print(\"f(0,15)=\",f(0,15))\n",
    "print(\"f(1,1)=\",f(1,1))\n",
    "print(\"f(19,58)=\",f(19,58))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(submitted)\n",
    "Pz = submitted.distribution_of_a_function(Pa_the, f)\n",
    "print(Pz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the random variable $f(X_0,X_1)$ has a 24.8% probability of being the string \"Zero\", a 14.2% probability of being the string \"Small\", and a 61% probability of being the string \"Big\".  Let's plot this probability mass function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot\n",
    "fig = plt.figure(figsize=(12,2))\n",
    "ax = fig.add_subplot(111)\n",
    "Zvals = ['Zero','Small','Big']\n",
    "ax.bar(np.arange(3), [Pz[z] for z in Zvals], tick_label=Zvals)\n",
    "ax.set_xlabel('Instance value $z=f(x_0,x_1)$')\n",
    "ax.set_ylabel('$P(f(X_0,X_1)=z)$')\n",
    "ax.set_title('Probability Mass Function of a Function of Two Random Variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grade'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grade your homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've reached this point, and all of the above sections work, then you're ready to try grading your homework!  Before you submit it to Gradescope, try grading it on your own machine.  This will run some visible test cases (which you can read in `tests/test_visible.py`), and compare the results to the solutions (which you can read in `solution.json`).\n",
    "\n",
    "The exclamation point (!) tells python to run the following as a shell command.  Obviously you don't need to run the code this way -- this usage is here just to remind you that you can also, if you wish, run this command in a terminal window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python grade.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code is working, then as shown above, the only error you get should be from the extra credit part (`test_extra.py`).\n",
    "\n",
    "If you got any other 'E' marks, it means that your code generated some runtime errors, and you need to debug those.\n",
    "\n",
    "If you got any 'F' marks, it means that your code ran without errors, but that it generated results that are different from the solutions in `solutions.json`.  Try debugging those differences.\n",
    "\n",
    "If neither of those things happened, and your result was a series of dots except for the one error associated with `test_extra.py`, then your code works perfectly.  \n",
    "\n",
    "If you're not sure, you can try running grade.py with the -j option.  This will produce a JSON results file, in which you should get a score of 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python grade.py -j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should try uploading `submitted.py` to <a href=\"https://www.gradescope.com/courses/486387\">Gradescope</a>.  \n",
    "\n",
    "Gradescope will run the same visible tests that you just ran on your own machine, plus some additional hidden tests.  It's possible that your code passes all the visible tests, but fails the hidden tests.  If that happens, then it probably means that you hard-coded a number into your function definition, instead of using the input parameter that you were supposed to use.  Debug by running your function with a variety of different input parameters, and see if you can get it to respond correctly in all cases.\n",
    "\n",
    "Once your code works perfectly on Gradescope, with no errors, then you are done with the MP.  Congratulations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On many of the machine problems (not all), extra credit of up to 10% will be available for doing a problem that goes a little bit beyond the material we've covered in lecture.\n",
    "\n",
    "On MP01, for extra credit, let's model the frequency of a word as a geometric random variable.  A geometric random variable, $Y$, is one whose pmf is given by $P(Y=y)=p(1-p)^y$ for all non-negative integer values of $y$, where $p$ is a parameter called the \"success probability\" or the \"stopping probability.\"\n",
    "\n",
    "In order to model an observed random variable ($X$) using a geometric random variable ($Y$), the easiest way to estimate the model is by calculating $E[X]$, then choosing the parameter $p$ so that $E[Y]=E[X]$.  The mean of a geometric random variable is $E[Y]=\\frac{1-p}{p}$.\n",
    "\n",
    "For extra credit, try estimating the parameter $p$ that matches the observed mean of a non-negative integer random variable.  The template code is in `extra.py`, which has just one function for you to complete, the function `estimate_geometric`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import extra, importlib\n",
    "importlib.reload(extra)\n",
    "help(extra.estimate_geometric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have the code working, you can test it by finding a geometric distribution model for the number of occurrences of the word \"a\": "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(extra)\n",
    "p, PY = extra.estimate_geometric(Pa)\n",
    "\n",
    "print('p=',p)\n",
    "print('The first five entries in the model pmf are',PY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(2,1,figsize=(14,4))\n",
    "axs[0].bar(np.arange(len(Pa)), Pa)\n",
    "axs[0].set_title('Observed probability mass function')\n",
    "axs[0].set_ylabel('$P(X=x)')\n",
    "axs[1].bar(np.arange(len(PY)), PY)\n",
    "axs[1].set_title('Geometric distribution model')\n",
    "axs[1].set_ylabel('$P(Y=x)$')\n",
    "axs[1].set_xlabel('Instance value, $x$, of the number of occurrences of the word \"the\"')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test your extra credit by running `grade.py` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python grade.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When that works, try uploading your file `extra.py` to Gradescope, under the heading `MP01 Extra Credit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
